{
  // ==========================================================================
  // GraphRAG Configuration - ACADEMIC RESEARCH
  // ==========================================================================
  // Converted from: academic_research.toml
  // VSCode: This file has autocomplete! Press Ctrl+Space for suggestions.
  // ==========================================================================

  "$schema": "../schema/graphrag-config.schema.json",
  "mode": {
    "approach": "semantic"
  },
  "general": {
    "input_document_path": "path/to/your/research_paper.pdf",
    "output_dir": "./output/academic_analysis",
    "log_level": "info",
    "max_threads": 4,
    "enable_profiling": true
  },
  "pipeline": {
    "workflows": [
      "extract_text",
      "extract_entities",
      "build_graph",
      "detect_communities"
    ],
    "parallel_execution": true,
    "text_extraction": {
      "chunk_size": 1024,
      "chunk_overlap": 200,
      "min_chunk_size": 256,
      "clean_control_chars": true,
      "normalize_whitespace": true
    },
    "entity_extraction": {
      "model_name": "llama3.1:8b",
      "temperature": 0.15,
      "max_tokens": 1200,
      "entity_types": [
        "RESEARCHER",
        "INSTITUTION",
        "THEORY",
        "METHODOLOGY",
        "DATASET",
        "EXPERIMENT",
        "FINDING",
        "HYPOTHESIS",
        "VARIABLE",
        "METRIC",
        "CITATION",
        "PUBLICATION",
        "CONCEPT",
        "FIELD",
        "TOOL",
        "STATISTIC",
        "MODEL",
        "ALGORITHM"
      ],
      "confidence_threshold": 0.7,
      "filters": {
        "min_entity_length": 2,
        "max_entity_length": 200,
        "allowed_patterns": [
          "^[A-Z][a-zA-Z\\s\\-\\.]+$",
          "^[A-Z][a-z]+\\s+(et\\s+al\\.?|and\\s+[A-Z][a-z]+)$",
          "^[A-Z][A-Z0-9\\-]+$",
          "^p\\s*[<>=]\\s*0\\.\\d+$",
          "^\\d+(\\.\\d+)?%$",
          "^[A-Za-z]+\\s*\\(\\d{4}\\)$"
        ],
        "excluded_patterns": [
          "^(the|and|but|for|with|from|that|this|however|therefore)$",
          "^(figure|table|section|chapter)$"
        ]
      }
    },
    "graph_building": {
      "relation_scorer": "cosine_similarity",
      "min_relation_score": 0.5,
      "max_connections_per_node": 30,
      "bidirectional_relations": true,
      "concept_centrality_boost": 1.4
    },
    "community_detection": {
      "algorithm": "leiden",
      "resolution": 0.7,
      "min_community_size": 3,
      "max_community_size": 25
    }
  },
  "text_processing": {
    "enabled": true,
    "chunk_size": 1024,
    "chunk_overlap": 200,
    "min_chunk_size": 256,
    "max_chunk_size": 2048,
    "normalize_whitespace": true,
    "remove_artifacts": true,
    "extract_keywords": true,
    "keyword_min_score": 0.2
  },
  "entity_extraction": {
    "enabled": true,
    "min_confidence": 0.7,
    "use_gleaning": true,
    "max_gleaning_rounds": 3,
    "gleaning_improvement_threshold": 0.1,
    "semantic_merging": true,
    "merge_similarity_threshold": 0.8,
    "automatic_linking": true,
    "linking_confidence_threshold": 0.75,
    "gleaning": {
      "focus_areas": [
        "THEORY",
        "METHODOLOGY",
        "FINDING",
        "HYPOTHESIS",
        "CONCEPT"
      ],
      "context_window": 300,
      "llm_temperature": 0.1,
      "academic_context": true,
      "citation_aware": true
    }
  },
  "graph_construction": {
    "enabled": true,
    "incremental_updates": true,
    "use_pagerank": true,
    "pagerank_damping": 0.85,
    "pagerank_iterations": 60,
    "pagerank_convergence": 0.0001,
    "extract_relationships": true,
    "relationship_confidence_threshold": 0.6,
    "research_relationship_boost": 1.3
  },
  "vector_processing": {
    "enabled": true,
    "embedding_model": "nomic-embed-text",
    "embedding_dimensions": 768,
    "use_hnsw_index": true,
    "hnsw_ef_construction": 250,
    "hnsw_m": 20,
    "similarity_threshold": 0.7
  },
  "query_processing": {
    "enabled": true,
    "use_advanced_pipeline": true,
    "use_intent_classification": true,
    "use_concept_extraction": true,
    "use_temporal_parsing": true,
    "confidence_threshold": 0.5,
    "intent_classification": {
      "research_patterns": [
        "research",
        "study",
        "investigation",
        "analysis",
        "examination"
      ],
      "method_patterns": [
        "method",
        "methodology",
        "approach",
        "technique",
        "procedure"
      ],
      "result_patterns": [
        "result",
        "finding",
        "outcome",
        "conclusion",
        "evidence"
      ],
      "theory_patterns": [
        "theory",
        "framework",
        "model",
        "hypothesis",
        "concept"
      ],
      "comparison_patterns": [
        "compare",
        "versus",
        "difference",
        "similarity",
        "contrast"
      ]
    },
    "prompt_templates": {
      "research": "Based on the following academic context, provide a detailed research analysis for: {query}\n\nContext:\n{context}\n\nResearch Analysis:",
      "methodology": "Analyze the research methodologies and approaches described in the context for: {query}\n\nContext:\n{context}\n\nMethodology Analysis:",
      "findings": "Summarize the research findings and their implications described in the context for: {query}\n\nContext:\n{context}\n\nFindings Summary:"
    }
  },
  "ollama": {
    "enabled": true,
    "host": "http://localhost",
    "port": 11434,
    "chat_model": "llama3.1:8b",
    "embedding_model": "nomic-embed-text",
    "timeout_seconds": 120,
    "max_retries": 3,
    "fallback_to_hash": false,
    "max_tokens": 1500,
    "temperature": 0.2,
    "generation": {
      "temperature": 0.25,
      "top_p": 0.9,
      "max_tokens": 2000,
      "stream": false
    }
  },
  "performance": {
    "batch_processing": true,
    "batch_size": 40,
    "worker_threads": 4,
    "memory_limit_mb": 8192,
    "cache_embeddings": true
  },
  "monitoring": {
    "enabled": true,
    "track_concept_accuracy": true,
    "track_citation_coverage": true,
    "track_research_coherence": true
  }
}